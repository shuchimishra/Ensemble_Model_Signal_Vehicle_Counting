{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import math\n",
    "import seaborn as sns\n",
    "sns.set_context('talk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Training Images and Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>car</th>\n",
       "      <th>bus</th>\n",
       "      <th>truck</th>\n",
       "      <th>train</th>\n",
       "      <th>motorcycle</th>\n",
       "      <th>bicycle</th>\n",
       "      <th>airplane</th>\n",
       "      <th>boat</th>\n",
       "      <th>traffic light</th>\n",
       "      <th>stop sign</th>\n",
       "      <th>vehicle</th>\n",
       "      <th>signal</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>000000000064.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>000000000073.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>000000000074.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>000000000081.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>000000000086.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   car  bus  truck  train  motorcycle  bicycle  airplane  boat  traffic light  \\\n",
       "0  1.0  0.0    1.0    0.0         0.0      0.0       0.0   0.0            0.0   \n",
       "1  0.0  0.0    0.0    0.0         2.0      0.0       0.0   0.0            0.0   \n",
       "2  0.0  0.0    0.0    0.0         0.0      1.0       0.0   0.0            0.0   \n",
       "3  0.0  0.0    0.0    0.0         0.0      0.0       1.0   0.0            0.0   \n",
       "4  0.0  0.0    0.0    0.0         1.0      0.0       0.0   0.0            0.0   \n",
       "\n",
       "   stop sign  vehicle  signal         file_name  \n",
       "0        1.0      2.0     1.0  000000000064.jpg  \n",
       "1        0.0      2.0     0.0  000000000073.jpg  \n",
       "2        0.0      1.0     0.0  000000000074.jpg  \n",
       "3        0.0      1.0     0.0  000000000081.jpg  \n",
       "4        0.0      1.0     0.0  000000000086.jpg  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_metadata = pd.read_csv('carnet_dataset/train/metadata.csv')\n",
    "train_metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score Images and Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000000000071.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000000000149.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000000000260.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000000000307.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000000000690.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          file_name\n",
       "0  000000000071.jpg\n",
       "1  000000000149.jpg\n",
       "2  000000000260.jpg\n",
       "3  000000000307.jpg\n",
       "4  000000000690.jpg"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score metadata defines the expected order of the photos in the submitted predictions file.\n",
    "\n",
    "score_metadata = pd.read_csv('carnet_dataset/score/metadata.csv')\n",
    "score_metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Tensorflow Dataset (Single Image, Labeled Segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-31 05:36:47.059623: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-31 05:36:47.112673: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-31 05:36:47.113531: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "# This configures the GPU to be used by Tensorflow.\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Splitting the train data into train, validate, and test \n",
    "from sklearn.model_selection import train_test_split\n",
    "train_metadata, test_metadata = train_test_split(train_metadata, test_size=0.20, random_state=42)\n",
    "train_metadata, val_metadata = train_test_split(train_metadata, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See Python Generator\n",
    "# https://peps.python.org/pep-0255/\n",
    "def build_generator_labeled_single(metadata: pd.DataFrame):\n",
    "    def generator():\n",
    "        for _, row in metadata.iterrows():\n",
    "            \n",
    "            training_path = 'carnet_dataset/train/images/' + row['file_name']\n",
    "            training_np = np.array(Image.open(training_path)).astype(np.float32)\n",
    "            \n",
    "            model_input = training_np\n",
    "            model_output_1 = (row[\"signal\"], )\n",
    "            # model_output_2 = (row[\"vehicle\"], )\n",
    "            yield (model_input, (model_output_1))\n",
    "            \n",
    "    return generator\n",
    "\n",
    "\n",
    "# See Tensorflow Dataset\n",
    "# https://www.tensorflow.org/api_docs/python/tf/data/Dataset\n",
    "def build_dataset_labeled_single(metadata: pd.DataFrame) -> tf.data.Dataset:\n",
    "    model_input = tf.TensorSpec(shape=(224, 224, 3), dtype=tf.float32)  # type: ignore\n",
    "    model_output = tf.TensorSpec(shape=(1, ), dtype=tf.float32)  # type: ignore\n",
    "\n",
    "    dataset_signature = (model_input, (model_output))\n",
    "\n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "        build_generator_labeled_single(metadata), \n",
    "        output_signature=dataset_signature\n",
    "    )\n",
    "\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See Python Generator\n",
    "# https://peps.python.org/pep-0255/\n",
    "def build_generator_labeled_single_vehicle(metadata: pd.DataFrame):\n",
    "    def generator():\n",
    "        for _, row in metadata.iterrows():\n",
    "            \n",
    "            training_path = 'carnet_dataset/train/images/' + row['file_name']\n",
    "            training_np = np.array(Image.open(training_path)).astype(np.float32)\n",
    "            \n",
    "            model_input = training_np\n",
    "            # model_output_1 = (row[\"signal\"], )\n",
    "            model_output_2 = (row[\"vehicle\"], )\n",
    "            yield (model_input, (model_output_2))\n",
    "            \n",
    "    return generator\n",
    "\n",
    "\n",
    "# See Tensorflow Dataset\n",
    "# https://www.tensorflow.org/api_docs/python/tf/data/Dataset\n",
    "def build_dataset_labeled_single_vehicle(metadata: pd.DataFrame) -> tf.data.Dataset:\n",
    "    model_input = tf.TensorSpec(shape=(224, 224, 3), dtype=tf.float32)  # type: ignore\n",
    "    model_output = tf.TensorSpec(shape=(1, ), dtype=tf.float32)  # type: ignore\n",
    "\n",
    "    dataset_signature = (model_input, (model_output))\n",
    "\n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "        build_generator_labeled_single_vehicle(metadata), \n",
    "        output_signature=dataset_signature\n",
    "    )\n",
    "\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-31 05:37:06.145756: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-31 05:37:06.146391: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-31 05:37:06.147302: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-31 05:37:06.148127: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-31 05:37:06.840309: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-31 05:37:06.841168: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-31 05:37:06.841977: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-31 05:37:06.842759: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10780 MB memory:  -> device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7\n"
     ]
    }
   ],
   "source": [
    "train_single_dataset = build_dataset_labeled_single(train_metadata).batch(batch_size)\n",
    "train_single_dataset_vehicle = build_dataset_labeled_single_vehicle(train_metadata).batch(batch_size)\n",
    "# model_input, (model_output_1, model_output_2) = next(iter(train_single_dataset))\n",
    "# display(model_input.shape, model_output_1.shape, model_output_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_single_dataset = build_dataset_labeled_single(val_metadata).batch(batch_size)\n",
    "val_single_dataset_vehicle = build_dataset_labeled_single_vehicle(val_metadata).batch(batch_size)\n",
    "# model_input, (model_output_1, model_output_2) = next(iter(val_single_dataset))\n",
    "# display(model_input.shape, model_output_1.shape, model_output_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_single_dataset = build_dataset_labeled_single(test_metadata).batch(batch_size)\n",
    "test_single_dataset_vehicle = build_dataset_labeled_single_vehicle(test_metadata).batch(batch_size)\n",
    "# model_input, (model_output_1, model_output_2) = next(iter(test_single_dataset))\n",
    "# display(model_input.shape, model_output_1.shape, model_output_2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Tensorflow Dataset (Single Image, Score Segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# See Python Generator\n",
    "# https://peps.python.org/pep-0255/\n",
    "\n",
    "def generator_score_single():\n",
    "    metadata = pd.read_csv('carnet_dataset/score/metadata.csv')\n",
    "    \n",
    "    for _, row in metadata.iterrows():\n",
    "        image_path = 'carnet_dataset/score/images/' + row['file_name']\n",
    "\n",
    "        image_np = np.array(Image.open(image_path)).astype(np.float32)\n",
    "\n",
    "        model_input = image_np\n",
    "        yield model_input\n",
    "\n",
    "\n",
    "# See Tensorflow Dataset\n",
    "# https://www.tensorflow.org/api_docs/python/tf/data/Dataset\n",
    "def build_dataset_score_single() -> tf.data.Dataset:\n",
    "    model_input = tf.TensorSpec(shape=(224, 224, 3), dtype=tf.float32)  # type: ignore\n",
    "\n",
    "    dataset_signature = model_input\n",
    "\n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "        generator_score_single, \n",
    "        output_signature=dataset_signature\n",
    "    )\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_single_dataset = build_dataset_score_single().batch(batch_size)\n",
    "# model_input = next(iter(score_single_dataset))\n",
    "# display(model_input.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Getting pre-trained MobileNet Architecture, \n",
    "### using global average pooling at the end and excluding the top dense layer\n",
    "# https://arxiv.org/pdf/1801.04381.pdf\n",
    "# https://keras.io/api/applications/mobilenet/#mobilenetv2-function\n",
    "eff_net = tf.keras.applications.EfficientNetV2B1(\n",
    "    include_top=False,\n",
    "    input_shape=(224, 224, 3),\n",
    "    pooling=\"avg\",\n",
    "    weights=\"imagenet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Freezing the parameters of the MobileNet layers\n",
    "eff_net.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See Keras Functional API\n",
    "# https://keras.io/guides/functional_api/\n",
    "\n",
    "### Three inputs: real image, generated image, caption embeddings\n",
    "inp = tf.keras.layers.Input((224, 224, 3))\n",
    "\n",
    "rescale = tf.keras.layers.Rescaling(1./255)\n",
    "\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomRotation((-1, 1)),\n",
    "    tf.keras.layers.RandomContrast((0, 1)),\n",
    "    tf.keras.layers.RandomHeight((-0.5, 0.5)),\n",
    "    tf.keras.layers.RandomWidth((-0.5, 0.5))\n",
    "    \n",
    "])\n",
    "\n",
    "img = tf.keras.models.Sequential([\n",
    "    rescale,\n",
    "    data_augmentation,\n",
    "    eff_net,\n",
    "])\n",
    "\n",
    "### Using MobileNet for the images and Dense layer architecture for the caption embeddings\n",
    "outputs = eff_net(inp)\n",
    "\n",
    "### Concatenating the three outputs and using Dence layers on top, with dropouts to avoid overfitting\n",
    "outputs_1 = tf.keras.layers.Dense(256, activation='relu')(outputs)\n",
    "# outputs_1 = tf.keras.layers.Dropout(rate = 0.2)(outputs_1)\n",
    "outputs_1 = tf.keras.layers.Dense(128, activation='relu')(outputs_1)\n",
    "# outputs_1 = tf.keras.layers.Dropout(rate = 0.25)(outputs_1)\n",
    "outputs_1 = tf.keras.layers.Dense(64, activation='relu')(outputs_1)\n",
    "# outputs_1 = tf.keras.layers.Dropout(rate = 0.25)(outputs_2)\n",
    "# outputs_1 = tf.keras.layers.Dense(32, activation='relu')(outputs_1)\n",
    "outputs_1 = tf.keras.layers.Dense(1)(outputs_1)\n",
    "\n",
    "# outputs_1 = tf.keras.layers.Dense(256, activation='relu')(outputs)\n",
    "# outputs_1 = tf.keras.layers.Dropout(rate = 0.2)(outputs_1)\n",
    "# outputs_1 = tf.keras.layers.Dense(128, activation='relu')(outputs_1)\n",
    "# outputs_1 = tf.keras.layers.Dropout(rate = 0.25)(outputs_1)\n",
    "# outputs_1 = tf.keras.layers.Dense(64, activation='relu')(outputs)\n",
    "# outputs_1 = tf.keras.layers.Dropout(rate = 0.25)(outputs_1)\n",
    "# outputs_2 = tf.keras.layers.Dense(32, activation='relu')(outputs)\n",
    "outputs_2 = tf.keras.layers.Dense(16, activation='relu')(outputs)\n",
    "outputs_2 = tf.keras.layers.Dense(8, activation='relu')(outputs_2)\n",
    "outputs_2 = tf.keras.layers.Dense(4, activation='relu')(outputs_2)\n",
    "outputs_2 = tf.keras.layers.Dense(2, activation='relu')(outputs_2)\n",
    "outputs_2 = tf.keras.layers.Dense(1)(outputs_2)\n",
    "\n",
    "model1 = tf.keras.models.Model(inputs=inp, outputs=[outputs_1])\n",
    "model2 = tf.keras.models.Model(inputs=inp, outputs=[outputs_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/setup/miniconda/envs/ucla_deeplearning/lib/python3.10/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "### Adam optimizer with 0.01 learning rate\n",
    "model1.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(\n",
    "        lr=0.001\n",
    "    ),\n",
    "    loss='mean_squared_error'\n",
    ")\n",
    "\n",
    "model2.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(\n",
    "        lr=0.001\n",
    "    ),\n",
    "    loss='mean_squared_error'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Checkpoint path \n",
    "checkpoint_path = \"weights/car_27_d1\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/128\n",
      "    109/Unknown - 78s 653ms/step - loss: 1.4388\n",
      "Epoch 1: val_loss improved from inf to 1.21313, saving model to weights/car_27_d1\n",
      "109/109 [==============================] - 104s 893ms/step - loss: 1.4388 - val_loss: 1.2131\n",
      "Epoch 2/128\n",
      "109/109 [==============================] - ETA: 0s - loss: 1.1862\n",
      "Epoch 2: val_loss improved from 1.21313 to 1.19553, saving model to weights/car_27_d1\n",
      "109/109 [==============================] - 96s 878ms/step - loss: 1.1862 - val_loss: 1.1955\n",
      "Epoch 3/128\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.9907\n",
      "Epoch 3: val_loss did not improve from 1.19553\n",
      "109/109 [==============================] - 95s 875ms/step - loss: 0.9907 - val_loss: 1.2291\n",
      "Epoch 4/128\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.7860\n",
      "Epoch 4: val_loss did not improve from 1.19553\n",
      "109/109 [==============================] - 95s 874ms/step - loss: 0.7860 - val_loss: 1.2637\n",
      "Epoch 5/128\n",
      "109/109 [==============================] - ETA: 0s - loss: 0.6384\n",
      "Epoch 5: val_loss did not improve from 1.19553\n",
      "109/109 [==============================] - 95s 873ms/step - loss: 0.6384 - val_loss: 1.3715\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f00516c0550>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "np.random.seed(11)\n",
    "tf.random.set_seed(11)\n",
    "\n",
    "### Callback to save model log / results after each epoch\n",
    "csv_logger = tf.keras.callbacks.CSVLogger(\"model27_d1_history_log.csv\", append=True)\n",
    "\n",
    "### Callback to save weights after every epoch i.e., checkpoint\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1, save_best_only=True, monitor = 'val_loss') \n",
    "\n",
    "### Callback to stop the training if there's no improvement in validation loss for 3 epochs\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "model1.fit(\n",
    "    train_single_dataset,\n",
    "    epochs=128,\n",
    "    shuffle=True,\n",
    "    validation_data=(val_single_dataset),\n",
    "    callbacks=[stop_early, cp_callback, csv_logger]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"weights/car_27_d2\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/128\n",
      "    109/Unknown - 79s 656ms/step - loss: 12.3840\n",
      "Epoch 1: val_loss improved from inf to 9.08405, saving model to weights/car_27_d2\n",
      "109/109 [==============================] - 105s 896ms/step - loss: 12.3840 - val_loss: 9.0840\n",
      "Epoch 2/128\n",
      "109/109 [==============================] - ETA: 0s - loss: 9.0927\n",
      "Epoch 2: val_loss improved from 9.08405 to 8.15117, saving model to weights/car_27_d2\n",
      "109/109 [==============================] - 96s 880ms/step - loss: 9.0927 - val_loss: 8.1512\n",
      "Epoch 3/128\n",
      "109/109 [==============================] - ETA: 0s - loss: 8.2008\n",
      "Epoch 3: val_loss improved from 8.15117 to 7.80022, saving model to weights/car_27_d2\n",
      "109/109 [==============================] - 95s 876ms/step - loss: 8.2008 - val_loss: 7.8002\n",
      "Epoch 4/128\n",
      "109/109 [==============================] - ETA: 0s - loss: 7.6604\n",
      "Epoch 4: val_loss improved from 7.80022 to 7.65554, saving model to weights/car_27_d2\n",
      "109/109 [==============================] - 96s 879ms/step - loss: 7.6604 - val_loss: 7.6555\n",
      "Epoch 5/128\n",
      "109/109 [==============================] - ETA: 0s - loss: 7.2362\n",
      "Epoch 5: val_loss improved from 7.65554 to 7.58871, saving model to weights/car_27_d2\n",
      "109/109 [==============================] - 95s 876ms/step - loss: 7.2362 - val_loss: 7.5887\n",
      "Epoch 6/128\n",
      "109/109 [==============================] - ETA: 0s - loss: 6.8920\n",
      "Epoch 6: val_loss improved from 7.58871 to 7.57605, saving model to weights/car_27_d2\n",
      "109/109 [==============================] - 95s 876ms/step - loss: 6.8920 - val_loss: 7.5760\n",
      "Epoch 7/128\n",
      "109/109 [==============================] - ETA: 0s - loss: 6.5556\n",
      "Epoch 7: val_loss did not improve from 7.57605\n",
      "109/109 [==============================] - 95s 874ms/step - loss: 6.5556 - val_loss: 7.5863\n",
      "Epoch 8/128\n",
      "109/109 [==============================] - ETA: 0s - loss: 6.2407\n",
      "Epoch 8: val_loss did not improve from 7.57605\n",
      "109/109 [==============================] - 95s 875ms/step - loss: 6.2407 - val_loss: 7.6801\n",
      "Epoch 9/128\n",
      "109/109 [==============================] - ETA: 0s - loss: 5.9253\n",
      "Epoch 9: val_loss did not improve from 7.57605\n",
      "109/109 [==============================] - 95s 876ms/step - loss: 5.9253 - val_loss: 7.8461\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0153454b20>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "np.random.seed(11)\n",
    "tf.random.set_seed(11)\n",
    "\n",
    "### Callback to save model log / results after each epoch\n",
    "csv_logger = tf.keras.callbacks.CSVLogger(\"model27_d2_history_log.csv\", append=True)\n",
    "\n",
    "### Callback to save weights after every epoch i.e., checkpoint\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1, save_best_only=True, monitor = 'val_loss') \n",
    "\n",
    "### Callback to stop the training if there's no improvement in validation loss for 3 epochs\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "model2.fit(\n",
    "    train_single_dataset_vehicle,\n",
    "    epochs=128,\n",
    "    shuffle=True,\n",
    "    validation_data=(val_single_dataset_vehicle),\n",
    "    callbacks=[stop_early, cp_callback, csv_logger]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"weights/car_27_d1\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loading the weights from previous checkpoint\n",
    "model1.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"weights/car_27_d2\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loading the weights from previous checkpoint\n",
    "model2.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred1 = model1.predict(val_single_dataset)\n",
    "val_pred2 = model2.predict(val_single_dataset_vehicle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_signal = []\n",
    "val_vehicle = []\n",
    "for i in range(len(val_pred1)):\n",
    "    if val_pred1[i][0]>0:\n",
    "        val_signal.append(val_pred1[i][0])\n",
    "    else:\n",
    "        val_signal.append(0)\n",
    "    if val_pred2[i][0]>0:\n",
    "        val_vehicle.append(val_pred2[i][0])\n",
    "    else:\n",
    "        val_vehicle.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1955249283399287\n",
      "7.576044090440667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "print(mean_squared_error(val_metadata[\"signal\"].values, val_pred1))\n",
    "print(mean_squared_error(val_metadata[\"vehicle\"].values, val_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1858136388895872\n",
      "7.576044090440667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "print(mean_squared_error(val_metadata[\"signal\"].values, val_signal))\n",
    "print(mean_squared_error(val_metadata[\"vehicle\"].values, val_vehicle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 25s 645ms/step - loss: 1.1955\n",
      "37/37 [==============================] - 24s 642ms/step - loss: 7.5760\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7.576045036315918"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Evaluating the model on validation set\n",
    "model1.evaluate(val_single_dataset, verbose = 1)\n",
    "model2.evaluate(val_single_dataset_vehicle, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 24s 649ms/step - loss: 1.2225\n",
      "37/37 [==============================] - 24s 646ms/step - loss: 7.7487\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7.748720169067383"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Evaluating the model on test set\n",
    "model1.evaluate(test_single_dataset, verbose = 1)\n",
    "model2.evaluate(test_single_dataset_vehicle, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 31s 640ms/step\n",
      "     42/Unknown - 29s 657ms/step"
     ]
    }
   ],
   "source": [
    "### Predicting the probabilities on score set\n",
    "score_y_hat1 = model1.predict(score_single_dataset, verbose = 1)\n",
    "score_y_hat2 = model2.predict(score_single_dataset, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = []\n",
    "vehicle = []\n",
    "for i in range(len(score_y_hat1)):\n",
    "    if score_y_hat1[i][0]>0:\n",
    "        signal.append(score_y_hat1[i][0])\n",
    "    else:\n",
    "        signal.append(0)\n",
    "    if score_y_hat2[i][0]>0:\n",
    "        vehicle.append(score_y_hat2[i][0])\n",
    "    else:\n",
    "        vehicle.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the model and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your predictions on the Score segment as a Pandas data frame into a variable named `score_y_hat`.\n",
    "# The data frame should contain 2 columns: signal and vehicle.\n",
    "# The following is an EXAMPLE of what this data frame could be.\n",
    "score_y_hat = pd.DataFrame({\n",
    "    'signal': signal,\n",
    "    'vehicle':vehicle\n",
    "})\n",
    "\n",
    "# Use the following asserts to check the type and shape of the final predictions.\n",
    "assert type(score_y_hat) == pd.DataFrame\n",
    "assert score_y_hat.shape == (score_metadata.shape[0], 2)\n",
    "assert (score_y_hat.columns == ['signal', 'vehicle']).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the following code to save the final predictions.\n",
    "import os \n",
    "model_dir = 'carnet_model'\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "score_y_hat.to_parquet(f'{model_dir}/score_y_hat.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "\n",
    "# os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Next, let's save the model's definition.\n",
    "import json\n",
    "with open(f'{model_dir}/keras_signal_model.json', 'w') as f:\n",
    "    f.write(json.dumps(json.loads(model1.to_json()), indent=True))\n",
    "    \n",
    "with open(f'{model_dir}/keras_vehicle_model.json', 'w') as f:\n",
    "    f.write(json.dumps(json.loads(model2.to_json()), indent=True))\n",
    "\n",
    "# Finally, let's save the learned parameters.\n",
    "model1.save_weights(f'{model_dir}/keras_parameters_signal_model.h5')\n",
    "model2.save_weights(f'{model_dir}/keras_parameters_vehicle_model.h5')\n",
    "# You now have the following files to be uploaded to Moodle:\n",
    "# 1. This notebook and any other Python code you used to train the final model.\n",
    "# 2. keras_model.json -- the model's definition\n",
    "# 3. keras_parameters.json -- the model's trained parameters\n",
    "# 4. score_y_hat.parquet - the model's output on the score dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, save each model's defition (JSON file) and parameters (H5 file).\n",
    "\n",
    "# You now have the following files to be submit:\n",
    "# 1. This notebook and any other Python code you used to train the final model.\n",
    "# 2. definitions of all trained models\n",
    "# 3. parameters of all trained models\n",
    "# 4. score_y_hat.parquet - the model's output on the score segment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
